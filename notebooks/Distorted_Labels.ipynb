{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dataset into 25% randomly and dividing it into 5 equal sets to apply different distortions and get labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is split into 5 equal sets to apply differents types of distortions to each set. These distortion types are as follows:\n",
    "- Brightness/Luminance\n",
    "- Contrast\n",
    "- Sharpness\n",
    "- Noise\n",
    "- Pixel Blocking\n",
    "\n",
    "The distortions will be applied to each set on different severity levels. Once the distortion is applied, a score will be given to each video based on how much distortion was applied and the score will be saved in a csv along with the type of distortion type, video name, severity score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import skimage as ski\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the paths of input and output folders.\n",
    "original_folder = 'EPIC-KITCHENS-100/EPIC-KITCHENS-100-train/train'\n",
    "output_folder = 'Code/Epic_vid_balanced_new_7Sept'\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new dataframe for storing details regarding the videos.\n",
    "\n",
    "df = pd.DataFrame(columns=['Video Name', 'Type', 'Degrade Type Factor', 'Quality Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the paths of the videos in the folder\n",
    "all_videos = [os.path.join(original_folder, video) for video in os.listdir(original_folder) if video.endswith('.mp4')]\n",
    "\n",
    "# Calculating the total number of videos in the folder and creating a subset of 25%\n",
    "total_videos = len(all_videos)\n",
    "subset_size = int(total_videos * 0.25)\n",
    "\n",
    "selected_videos = random.sample(all_videos, subset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating 5 different sets for each distortion type\n",
    "distort_set_size = subset_size // 5\n",
    "\n",
    "# brightness_set = random.sample(selected_videos, distort_set_size)\n",
    "# contrast_set = random.sample(selected_videos, distort_set_size)\n",
    "# sharpness_set = random.sample(selected_videos, distort_set_size)\n",
    "# noise_set = random.sample(selected_videos, distort_set_size)\n",
    "# blockiness_set = random.sample(selected_videos, distort_set_size)\n",
    "\n",
    "# Make a copy of selected_videos to modify safely\n",
    "remaining_videos = selected_videos.copy()\n",
    "\n",
    "# Create each set by sampling from the remaining available videos\n",
    "brightness_set = random.sample(remaining_videos, distort_set_size)\n",
    "# Remove selected videos from the remaining pool\n",
    "remaining_videos = [video for video in remaining_videos if video not in brightness_set]\n",
    "\n",
    "contrast_set = random.sample(remaining_videos, distort_set_size)\n",
    "remaining_videos = [video for video in remaining_videos if video not in contrast_set]\n",
    "\n",
    "sharpness_set = random.sample(remaining_videos, distort_set_size)\n",
    "remaining_videos = [video for video in remaining_videos if video not in sharpness_set]\n",
    "\n",
    "noise_set = random.sample(remaining_videos, distort_set_size)\n",
    "remaining_videos = [video for video in remaining_videos if video not in noise_set]\n",
    "\n",
    "blockiness_set = random.sample(remaining_videos, distort_set_size)\n",
    "remaining_videos = [video for video in remaining_videos if video not in blockiness_set]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {\"Brightness Set\" : brightness_set,\n",
    "        \"Contrast Set\" : contrast_set,\n",
    "        \"Sharpness Set\" : sharpness_set,\n",
    "        \"Noise Set\": noise_set,\n",
    "        \"Pixel Blocking Set\": blockiness_set}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected = pd.DataFrame(data = dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected.to_csv(\"selected_videos.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(set(blockiness_set)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LUMINANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to change luminance of the video\n",
    "\n",
    "def adjust_luminance(frame, luminance_factor=1.0):\n",
    "\n",
    "    # Convert the frame from BGR to YUV color space\n",
    "    yuv_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2YUV)\n",
    "\n",
    "    # Split the channels\n",
    "    y, u, v = cv2.split(yuv_frame)\n",
    "\n",
    "    # Apply luminance adjustment\n",
    "    y = cv2.convertScaleAbs(y, alpha=luminance_factor, beta=0)\n",
    "\n",
    "    # Merge the channels back\n",
    "    adjusted_yuv_frame = cv2.merge((y, u, v))\n",
    "\n",
    "    # Convert back to BGR color space\n",
    "    adjusted_frame = cv2.cvtColor(adjusted_yuv_frame, cv2.COLOR_YUV2BGR)\n",
    "    \n",
    "    return adjusted_frame\n",
    "\n",
    "\n",
    "def luminance_quality_score(luminance_factor):\n",
    "    \"\"\"\n",
    "    Calculate a quality score between 0 and 1 based on the luminance adjustment factor.\n",
    "    \"\"\"\n",
    "    if luminance_factor < 1:\n",
    "        return luminance_factor  # The factor itself is between 0 and 1, which can directly represent the score.\n",
    "    else:  # luminance_factor > 1\n",
    "        return max(0, 1 - ((luminance_factor - 1.1) / (3 - 1.1)))  # Linearly scale the score between 1 and 0\n",
    "    \n",
    "\n",
    "def change_video_luminance(video_path, output_path):\n",
    "    \"\"\"\n",
    "    Adjust the luminance of a video.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video {video_path}\")\n",
    "        return\n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, cap.get(cv2.CAP_PROP_FPS),\n",
    "                          (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
    "    \n",
    "    # Randomly choose between increasing the luminance or not\n",
    "    choice = random.choice(['increase','decrease'])\n",
    "    \n",
    "    # Increase luminance with a factor > 1 (e.g., luminance_factor = 1.5)\n",
    "    # Decrease luminance with a factor < 1 (e.g., luminance_factor = 0.7)\n",
    "    if choice == \"increase\":\n",
    "        luminance = random.triangular(1.1,3)\n",
    "    elif choice == \"decrease\":\n",
    "        luminance = random.random()\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Adjust the luminance of the frame\n",
    "        adjusted_frame = adjust_luminance(frame, luminance_factor=luminance)\n",
    "\n",
    "        # Write the adjusted frame to output\n",
    "        out.write(adjusted_frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "    # Calculate quality score for the entire video\n",
    "    quality_score = luminance_quality_score(luminance)\n",
    "\n",
    "    return quality_score , luminance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Videos:   0%|          | 0/3360 [00:00<?, ?video/s]C:\\Users\\maury\\AppData\\Local\\Temp\\ipykernel_25204\\2748888909.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
      "Processing Videos: 100%|██████████| 3360/3360 [04:20<00:00, 12.89video/s]\n"
     ]
    }
   ],
   "source": [
    "# Creating bad data by changing brightness\n",
    "\n",
    "good_vids_brightness = random.sample(brightness_set, len(brightness_set) // 4)\n",
    "\n",
    "for video in tqdm.tqdm(brightness_set, desc=\"Processing Videos\", unit=\"video\"):\n",
    "    video_name = os.path.basename(video).split('\\\\')[-1]\n",
    "    if video in good_vids_brightness:\n",
    "        shutil.copy(video, output_folder)\n",
    "        quality_score = 1  # Assign a perfect score to original videos\n",
    "        new_row = {'Video Name': video_name, \n",
    "                   'Type' : 'Luminance',\n",
    "                   'Degrade Type Factor' : np.nan,\n",
    "                   'Quality Score': quality_score}\n",
    "        df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "    else:\n",
    "        bad_video_path = os.path.join(output_folder, f\"{video_name}\")\n",
    "        quality_score, luminance_factor = change_video_luminance(video, bad_video_path)\n",
    "        new_row = {'Video Name': video_name,\n",
    "                   'Type' : 'Luminance',\n",
    "                   'Degrade Type Factor' : luminance_factor,\n",
    "                   'Quality Score': quality_score}\n",
    "        df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONTRAST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to change contrast of the video\n",
    "\n",
    "def contrast_quality_score(alpha):\n",
    "    \"\"\"\n",
    "    Calculate a quality score between 0 and 1 based on the contrast adjustment factor.\n",
    "    \"\"\"\n",
    "    if alpha < 1:\n",
    "        return alpha  # The factor itself is between 0 and 1, which can directly represent the score.\n",
    "    else:  # contrast_factor > 1\n",
    "        return max(0, 1 - ((alpha - 1.1) / (3 - 1.1)))  # Linearly scale the score between 1 and 0\n",
    "\n",
    "\n",
    "def adjust_contrast_in_video(video_path, output_path):\n",
    "    \"\"\"\n",
    "    Adjust the contrast of a video.\n",
    "\n",
    "    Parameters:\n",
    "    - video_path: Path to the input video file.\n",
    "    - output_path: Path to save the output video file.\n",
    "    - alpha: Contrast control (1.0-3.0), default is 1.0.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video {video_path}\")\n",
    "        return\n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, cap.get(cv2.CAP_PROP_FPS),\n",
    "                          (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
    "    \n",
    "    # Randomly choose between increasing the contrast or not\n",
    "    choice = random.choice(['increase','decrease'])\n",
    "    \n",
    "    # Increase contrast by setting alpha > 1 (e.g., alpha = 1.5)\n",
    "    # Decrease contrast by setting alpha < 1 (e.g., alpha = 0.7)\n",
    "    if choice == \"increase\":\n",
    "        alpha = random.triangular(1.1,3)\n",
    "    elif choice == \"decrease\":\n",
    "        alpha = random.random()\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Adjust the contrast of the frame\n",
    "        contrast_frame = cv2.convertScaleAbs(frame, alpha=alpha)\n",
    "\n",
    "        # Write the contrast-adjusted frame to output\n",
    "        out.write(contrast_frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "    # Calculate quality score for the entire video\n",
    "    quality_score = contrast_quality_score(alpha)\n",
    "\n",
    "    return quality_score , alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Videos: 100%|██████████| 3360/3360 [02:53<00:00, 19.33video/s]\n"
     ]
    }
   ],
   "source": [
    "# Creating bad data by changing contrast\n",
    "\n",
    "good_vids_contrast = random.sample(contrast_set, len(contrast_set) // 4)\n",
    "\n",
    "for video in tqdm.tqdm(contrast_set, desc=\"Processing Videos\", unit=\"video\"):\n",
    "    video_name = os.path.basename(video).split('\\\\')[-1]\n",
    "    if video in good_vids_contrast:\n",
    "        shutil.copy(video, output_folder)\n",
    "        quality_score = 1  # Assign a perfect score to original videos\n",
    "        new_row = {'Video Name': video_name, \n",
    "                   'Type' : 'Contrast',\n",
    "                   'Degrade Type Factor' : np.nan,\n",
    "                   'Quality Score': quality_score}\n",
    "        df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "    else:\n",
    "        bad_video_path = os.path.join(output_folder, f\"{video_name}\")\n",
    "        quality_score, contrast_factor = adjust_contrast_in_video(video, bad_video_path)\n",
    "        new_row = {'Video Name': video_name, \n",
    "                   'Type' : 'Contrast',\n",
    "                   'Degrade Type Factor' : contrast_factor,\n",
    "                   'Quality Score': quality_score}\n",
    "        df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SHARPNESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_blur(video_path, output_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video {video_path}\")\n",
    "        return\n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, cap.get(cv2.CAP_PROP_FPS),\n",
    "                          (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
    "    \n",
    "    # Randomly choose a blur factor between 1 and 10\n",
    "    # sigma closer to 10 blurs the video drastically.\n",
    "    sigma = random.randint(1, 10)\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Apply Gaussian blur using skimage\n",
    "        blurred = ski.filters.gaussian(frame, sigma=sigma, truncate=3.5, channel_axis=-1)\n",
    "\n",
    "        # Convert the float image back to uint8 format for OpenCV compatibility\n",
    "        blurred = (blurred * 255).astype(np.uint8)\n",
    "        \n",
    "        # Write the blurred frame to output\n",
    "        out.write(blurred)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "    # Calculate the quality score based on the blur factor\n",
    "    quality_score = max(0, 1 - (sigma / 10))\n",
    "\n",
    "    return quality_score, sigma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Videos: 100%|██████████| 3360/3360 [39:13<00:00,  1.43video/s]  \n"
     ]
    }
   ],
   "source": [
    "# Creating bad data adding blur to the video\n",
    "\n",
    "good_vids_sharpness = random.sample(sharpness_set, len(sharpness_set) // 4)\n",
    "\n",
    "for video in tqdm.tqdm(sharpness_set, desc=\"Processing Videos\", unit=\"video\"):\n",
    "    video_name = os.path.basename(video).split('\\\\')[-1]\n",
    "    if video in good_vids_sharpness:\n",
    "        shutil.copy(video, output_folder)\n",
    "        quality_score = 1  # Assign a perfect score to original videos\n",
    "        new_row = {'Video Name': video_name, \n",
    "                   'Type' : 'Sharpness',\n",
    "                   'Degrade Type Factor' : np.nan,\n",
    "                   'Quality Score': quality_score}\n",
    "        df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "    else:\n",
    "        bad_video_path = os.path.join(output_folder, f\"{video_name}\")\n",
    "        quality_score, sharpness_factor = apply_blur(video, bad_video_path)\n",
    "        new_row = {'Video Name': video_name, \n",
    "                   'Type' : 'Sharpness',\n",
    "                   'Degrade Type Factor' : sharpness_factor,\n",
    "                   'Quality Score': quality_score}\n",
    "        df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_noise(video_path, output_path):\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video {video_path}\")\n",
    "        return\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, cap.get(cv2.CAP_PROP_FPS),\n",
    "                          (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
    "    \n",
    "    # Randomly choose a noise factor between 0 and 1\n",
    "    # noise_level closer to 1 creates a more noiser video.\n",
    "    noise_level = random.uniform(0.1, 1)\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Apply Gaussian noise\n",
    "        # noise = np.random.normal(0, noise_level, frame.shape).astype(np.uint8)\n",
    "        # noisy_frame = cv2.add(frame, noise)\n",
    "\n",
    "        # Apply Speckle noise\n",
    "        noise = np.random.normal(0, noise_level, frame.shape)\n",
    "        noisy_frame = frame + frame * noise\n",
    "        noisy_frame = np.clip(noisy_frame, 0, 255).astype(np.uint8)\n",
    "        \n",
    "        # Write the noisy frame to output\n",
    "        out.write(noisy_frame)\n",
    "        \n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "    quality_score = 1 - (noise_level - 0.1) / (1 - 0.1)\n",
    "\n",
    "    return quality_score, noise_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Videos: 100%|██████████| 3360/3360 [31:45<00:00,  1.76video/s]  \n"
     ]
    }
   ],
   "source": [
    "# Creating bad data by adding noise to the video\n",
    "\n",
    "good_vids_noise = random.sample(noise_set, len(noise_set) // 4)\n",
    "\n",
    "for video in tqdm.tqdm(noise_set, desc=\"Processing Videos\", unit=\"video\"):\n",
    "    video_name = os.path.basename(video).split('\\\\')[-1]\n",
    "    if video in good_vids_noise:\n",
    "        shutil.copy(video, output_folder)\n",
    "        quality_score = 1  # Assign a perfect score to original videos\n",
    "        new_row = {'Video Name': video_name, \n",
    "                   'Type' : 'Noise',\n",
    "                   'Degrade Type Factor' : np.nan,\n",
    "                   'Quality Score': quality_score}\n",
    "        df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "    else:\n",
    "        bad_video_path = os.path.join(output_folder, f\"{video_name}\")\n",
    "        quality_score, noise_factor = apply_noise(video, bad_video_path)\n",
    "        new_row = {'Video Name': video_name, \n",
    "                   'Type' : 'Noise',\n",
    "                   'Degrade Type Factor' : noise_factor,\n",
    "                   'Quality Score': quality_score}\n",
    "        df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BLOCKINESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def apply_pixel_blocking(frame, block_size):\n",
    "#     \"\"\"\n",
    "#     Apply pixel blocking (pixelation) to a frame.\n",
    "    \n",
    "#     Parameters:\n",
    "#     - frame: The input video frame (numpy array).\n",
    "#     - block_size: The size of each block of pixels.\n",
    "    \n",
    "#     Returns:\n",
    "#     - pixelated_frame: The pixelated version of the input frame.\n",
    "#     \"\"\"\n",
    "#     (h, w) = frame.shape[:2]  # Get the height and width of the frame\n",
    "\n",
    "#     # Calculate the number of blocks along each dimension\n",
    "#     x_steps = np.arange(0, w, block_size)\n",
    "#     y_steps = np.arange(0, h, block_size)\n",
    "    \n",
    "#     # Copy the frame to create a pixelated version\n",
    "#     pixelated_frame = frame.copy()\n",
    "\n",
    "#     # Loop through each block position\n",
    "#     for x in x_steps:\n",
    "#         for y in y_steps:\n",
    "#             # Determine the block region\n",
    "#             x_end = min(x + block_size, w)\n",
    "#             y_end = min(y + block_size, h)\n",
    "            \n",
    "#             # Extract the block region\n",
    "#             block = frame[y:y_end, x:x_end]\n",
    "            \n",
    "#             # Compute the mean color of the block\n",
    "#             (B, G, R) = [int(x) for x in np.mean(block, axis=(0, 1))]\n",
    "            \n",
    "#             # Assign the mean color to all pixels in the block\n",
    "#             pixelated_frame[y:y_end, x:x_end] = (B, G, R)\n",
    "    \n",
    "#     return pixelated_frame\n",
    "\n",
    "# def apply_pixel_blocking_to_video(video_path, output_path):\n",
    "#     \"\"\"\n",
    "#     Apply pixel blocking to a video.\n",
    "    \n",
    "#     Parameters:\n",
    "#     - video_path: Path to the input video file.\n",
    "#     - output_path: Path to save the output video file.\n",
    "#     - block_size: The size of each block of pixels.\n",
    "#     \"\"\"\n",
    "#     cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "#     if not cap.isOpened():\n",
    "#         print(f\"Error: Could not open video {video_path}\")\n",
    "#         return\n",
    "\n",
    "#     fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "#     out = cv2.VideoWriter(output_path, fourcc, cap.get(cv2.CAP_PROP_FPS),\n",
    "#                           (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
    "    \n",
    "#     # Randomly choose a block_size between 1 and 10\n",
    "#     # block_size closer to 10 creates more blocky videos.\n",
    "#     block_size = random.randint(1, 10)\n",
    "\n",
    "#     while True:\n",
    "#         ret, frame = cap.read()\n",
    "#         if not ret:\n",
    "#             break\n",
    "\n",
    "#         # Apply pixel blocking to the frame\n",
    "#         pixelated_frame = apply_pixel_blocking(frame, block_size=block_size)\n",
    "\n",
    "#         # Write the pixelated frame to output\n",
    "#         out.write(pixelated_frame)\n",
    "\n",
    "#     cap.release()\n",
    "#     out.release()\n",
    "\n",
    "#     # Calculate the quality score based on the block size factor\n",
    "#     quality_score = max(0, 1 - (block_size / 10))\n",
    "\n",
    "#     return quality_score, block_size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "def apply_pixel_blocking(frame, block_size):\n",
    "    \"\"\"\n",
    "    Apply pixel blocking (pixelation) to a frame using OpenCV's resize method.\n",
    "    \n",
    "    Parameters:\n",
    "    - frame: The input video frame (numpy array).\n",
    "    - block_size: The size of each block of pixels.\n",
    "    \n",
    "    Returns:\n",
    "    - pixelated_frame: The pixelated version of the input frame.\n",
    "    \"\"\"\n",
    "    (h, w) = frame.shape[:2]\n",
    "    \n",
    "    # Resize down by the block size, then resize up to original size\n",
    "    temp = cv2.resize(frame, (w // block_size, h // block_size), interpolation=cv2.INTER_LINEAR)\n",
    "    pixelated_frame = cv2.resize(temp, (w, h), interpolation=cv2.INTER_NEAREST)\n",
    "    \n",
    "    return pixelated_frame\n",
    "\n",
    "def process_frame_batch(frames, block_size):\n",
    "    \"\"\"\n",
    "    Helper function to apply pixel blocking to a batch of frames.\n",
    "    \"\"\"\n",
    "    return [apply_pixel_blocking(frame, block_size) for frame in frames]\n",
    "\n",
    "def apply_pixel_blocking_to_video(video_path, output_path):\n",
    "    \"\"\"\n",
    "    Apply pixel blocking to a video using multi-threading with batch processing.\n",
    "    \n",
    "    Parameters:\n",
    "    - video_path: Path to the input video file.\n",
    "    - output_path: Path to save the output video file.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video {video_path}\")\n",
    "        return\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, cap.get(cv2.CAP_PROP_FPS),\n",
    "                          (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
    "\n",
    "    # Randomly choose a block_size between 1 and 10\n",
    "    block_size = random.randint(1, 10)\n",
    "\n",
    "    # Read all frames into memory\n",
    "    frames = []\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frames.append(frame)\n",
    "\n",
    "    # Process frames in batches using ThreadPoolExecutor\n",
    "    batch_size = 10  # Process 10 frames in parallel\n",
    "    with ThreadPoolExecutor(max_workers=4) as executor:  # You can adjust the number of workers\n",
    "        futures = []\n",
    "        for i in range(0, len(frames), batch_size):\n",
    "            batch = frames[i:i+batch_size]\n",
    "            futures.append(executor.submit(process_frame_batch, batch, block_size))\n",
    "\n",
    "        for future in as_completed(futures):\n",
    "            processed_frames = future.result()\n",
    "            for processed_frame in processed_frames:\n",
    "                out.write(processed_frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "    # Calculate the quality score based on the block size factor\n",
    "    quality_score = max(0, 1 - (block_size / 10))\n",
    "\n",
    "    return quality_score, block_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Videos: 100%|██████████| 3360/3360 [03:57<00:00, 14.14video/s]\n"
     ]
    }
   ],
   "source": [
    "# Creating bad data by applying pixel blocking\n",
    "\n",
    "good_vids_blockiness = random.sample(blockiness_set, len(blockiness_set) // 4)\n",
    "\n",
    "for video in tqdm.tqdm(blockiness_set, desc=\"Processing Videos\", unit=\"video\"):\n",
    "    video_name = os.path.basename(video).split('\\\\')[-1]\n",
    "    if video in good_vids_blockiness:\n",
    "        shutil.copy(video, output_folder)\n",
    "        quality_score = 1  # Assign a perfect score to original videos\n",
    "        new_row = {'Video Name': video_name, \n",
    "                   'Type' : 'Blockiness',\n",
    "                   'Degrade Type Factor' : np.nan,\n",
    "                   'Quality Score': quality_score}\n",
    "        df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "    else:\n",
    "        bad_video_path = os.path.join(output_folder, f\"{video_name}\")\n",
    "        quality_score, blockiness_factor = apply_pixel_blocking_to_video(video, bad_video_path)\n",
    "        new_row = {'Video Name': video_name, \n",
    "                   'Type' : 'Blockiness',\n",
    "                   'Degrade Type Factor' : blockiness_factor,\n",
    "                   'Quality Score': quality_score}\n",
    "        df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the dataframe as csv\n",
    "df.to_csv(\"balanced_dataset_details_7thSept.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
